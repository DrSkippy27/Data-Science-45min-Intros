# Intro to ``scikit-learn``

2014-04-04, Josh Montague


A short and basic introduction to the ``sklearn`` API interface and a couple of very simple examples of using an estimator on some built-in sample data. 

The capability of the full [``sklearn`` package](http://scikit-learn.org/stable/index.html) is pretty mind-blowing; this Notebook aims for the lowest hanging fruit, because the same framework is used for the advanced use-cases. This is certainly one of the strengths of ``sklearn``. Note that these materials do not go into explaining *what* the various estimators are doing or how the algorithm works. For those discussions, definitely see the other materials in [this repository](https://github.com/DrSkippy27/Data-Science-45min-Intros) and the [official documentation](http://scikit-learn.org/stable/documentation.html).

This session was built using: 

- Python 2.7 
- IPython 1.2
- matplotlib 1.3
- numpy 1.8
- sklearn 0.14

----

## Overview 

The majority of this material was collected by combining pieces of the official docs (which are possibly the pinnacle of package documentation) and assorted other online materials. To get some of the terminology down, the general framework is as follows...

Generally, we have $n$ samples of data, and trying to predict properties of unknown data. If each sample is more than a single number, it has *features*

### supervised learning

- regression

    - ex
        
- classification

    - ex
        

### unsupervised learning

- clustering

    - ex
        
- dimensionality reduction

    - ex
    
    
training v. testing sets 
